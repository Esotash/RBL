{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1z3sxi4UJqoE-d6CzygQChn2ZqJiHnWJ5","authorship_tag":"ABX9TyOLMUVsuXLKorLmmbl+parM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fD4nU5TIZhse"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout"]},{"cell_type":"code","source":["# Load data from NSE BhavcopyFTP\n","df = pd.read_csv('nse_stock_data')\n","\n","# Preprocess data\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_data = scaler.fit_transform(df['Close'].values.reshape(-1, 1))\n","\n","# Create sequences\n","X_train = []\n","y_train = []\n","n_future = 1  # Number of days to predict\n","n_past = 60   # Number of past days to use\n","for i in range(n_past, len(scaled_data) - n_future + 1):\n","    X_train.append(scaled_data[i - n_past:i, 0])\n","    y_train.append(scaled_data[i + n_future - 1:i + n_future, 0])\n","X_train, y_train = np.array(X_train), np.array(y_train)\n","\n","# Reshape data for LSTM\n","X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"XO27w9qUdoDZ","executionInfo":{"status":"error","timestamp":1726996940541,"user_tz":-330,"elapsed":976,"user":{"displayName":"Pranav Bhavsar","userId":"03342781595821087385"}},"outputId":"b9090d92-c215-4380-d6e3-fa7f692c11dd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-32b6d8f6b219>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data from NSE BhavcopyFTP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nse_stock_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"mhh43WXHZA8A","executionInfo":{"status":"error","timestamp":1728730945650,"user_tz":-330,"elapsed":1458,"user":{"displayName":"Pranav Bhavsar","userId":"03342781595821087385"}},"outputId":"95e4f1c5-e6d8-4613-c3ac-484c7dcca07f"},"execution_count":1,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Nominal Future Value (SIP)'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-185db3d387df>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Calculate future values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nominal Future Value (SIP)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonthly_rate_sip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_investment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nominal Future Value (SPY)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonthly_rate_spy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_investment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nominal Future Value (QQQ)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonthly_rate_qqq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_investment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Nominal Future Value (SIP)'"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Ve1T9-Pbdn2d"}},{"cell_type":"code","source":[],"metadata":{"id":"Tx19Hg-w1ox6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Import Required Libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","import matplotlib.pyplot as plt"],"metadata":{"id":"fTzRpzQxiGu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/NSE50.csv')"],"metadata":{"id":"cIiIrm2niHo3","executionInfo":{"status":"error","timestamp":1726996955513,"user_tz":-330,"elapsed":1793,"user":{"displayName":"Pranav Bhavsar","userId":"03342781595821087385"}},"outputId":"79ed9529-9d01-4a50-bac1-b55472828f57","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/NSE50.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-f7533ee58d10>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/NSE50.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/NSE50.csv'"]}]},{"cell_type":"code","source":["print(\"First few rows of the dataset:\")\n","print(df.head())"],"metadata":{"id":"Al7p3EbKv9vV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"RJB4iXYLiK3W"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n"],"metadata":{"id":"3SJOp1dkj5Gr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/NSE50.csv')"],"metadata":{"id":"9UVK5E7aqZYO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"TSE5OMbsymTH"}},{"cell_type":"code","source":["plt.plot(data['Close'])\n","plt.show()\n"],"metadata":{"id":"Fys4CBcRq6Pn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3oln2R9jrAsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_data_len = int(np.ceil(len(scaled_data) * 0.8))\n","\n","train_data = scaled_data[0:training_data_len, :]\n"],"metadata":{"id":"gXNxCxjnrPZ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataset(data, time_step=60):\n","    x_data, y_data = [], []\n","    for i in range(time_step, len(data)):\n","        x_data.append(data[i-time_step:i, 0])\n","        y_data.append(data[i, 0])\n","    return np.array(x_data), np.array(y_data)\n","\n","x_train, y_train = create_dataset(train_data)\n"],"metadata":{"id":"9ggjsZYrrRz9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"],"metadata":{"id":"U8QCwP8QrUQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n","model.add(LSTM(units=50, return_sequences=False))\n","model.add(Dense(units=25))\n","model.add(Dense(units=1))\n"],"metadata":{"id":"iTp8OoNrrWbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = scaled_data[training_data_len - 60:, :]\n","x_test, y_test = create_dataset(test_data)\n","\n","x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n"],"metadata":{"id":"5OrC0JxcrZjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(x_test)\n","predictions = scaler.inverse_transform(predictions)\n"],"metadata":{"id":"dwm2i07YrcuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rmse = np.sqrt(np.mean(predictions - y_test) ** 2)\n","print(f'Root Mean Squared Error: {rmse}')\n"],"metadata":{"id":"_402qWHqrgxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = data[:training_data_len]\n","valid = data[training_data_len:]\n","valid['Predictions'] = predictions\n","\n","plt.figure(figsize=(16,8))\n","plt.plot(train['Close'])\n","plt.plot(valid[['Close', 'Predictions']])\n","plt.show()\n"],"metadata":{"id":"jJfFtPLVrjQt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of days into the future to predict\n","future_days = 30\n","\n","# Get the last 'n' time steps from the training data\n","last_n_days = data['Close'][-60:].values\n","last_n_days_scaled = scaler.transform(last_n_days.reshape(-1,1))\n","\n","# Create a list to store predicted values\n","future_predictions = []\n","\n","# Predict for the next 'future_days' days\n","for i in range(future_days):\n","    # Reshape the last n steps\n","    X_input = np.array(last_n_days_scaled[-60:])\n","    X_input = np.reshape(X_input, (1, X_input.shape[0], 1))\n","\n","    # Predict the next value\n","    predicted_value = model.predict(X_input)\n","\n","    # Store the predicted value\n","    future_predictions.append(predicted_value[0,0])\n","\n","    # Append the predicted value to last_n_days_scaled to continue predicting\n","    last_n_days_scaled = np.append(last_n_days_scaled, predicted_value)\n","\n","    # Ensure that last_n_days_scaled always contains only the last 60 steps\n","    last_n_days_scaled = last_n_days_scaled[-60:]\n","\n","# Inverse scale the predicted values\n","future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n","\n","# Print the predicted future stock prices\n","print(future_predictions)\n"],"metadata":{"id":"BzvK_e3_spEm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a date range for the future predictions\n","last_date = pd.to_datetime(data.index[-1])\n","future_dates = pd.date_range(last_date, periods=future_days, freq='B')  # 'B' is for business days\n","\n","# Create a DataFrame for future predictions\n","future_df = pd.DataFrame(future_predictions, index=future_dates, columns=['Predicted Close'])\n","\n","# Plot the existing data along with future predictions\n","plt.figure(figsize=(16,8))\n","plt.plot(data['Close'], label=\"Historical Prices\")\n","plt.plot(future_df['Predicted Close'], label=\"Future Predictions\")\n","plt.title(\"Stock Price Prediction\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Stock Price\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"GRVIB9Azss0W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"1HawaCR5ssm2"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","\n","# Use the 'Close' column for prediction\n","close_data = data['Close'].values.reshape(-1, 1)\n","\n","# Scale the data\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_data = scaler.fit_transform(close_data)\n","\n","# Split the data into training and testing sets (80% training)\n","training_data_len = int(np.ceil(len(scaled_data) * 0.8))\n","train_data = scaled_data[0:training_data_len, :]\n","\n","# Create the training dataset\n","def create_dataset(data, time_step=60):\n","    X, y = [], []\n","    for i in range(time_step, len(data)):\n","        X.append(data[i-time_step:i, 0])\n","        y.append(data[i, 0])\n","    return np.array(X), np.array(y)\n","\n","# Create the X_train and y_train datasets\n","time_step = 60\n","X_train, y_train = create_dataset(train_data, time_step)\n","\n","# Reshape the X_train data for the LSTM model\n","X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","\n","# Now I'll proceed to build and train the LSTM model.\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n","model.add(LSTM(units=50, return_sequences=False))\n","model.add(Dense(units=25))\n","model.add(Dense(units=1))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","model.fit(X_train, y_train, batch_size=64, epochs=10)\n","\n","# Use the trained model for future predictions\n","# Prepare the test dataset (last 60 time steps) for future predictions\n","last_n_days_scaled = scaled_data[-time_step:]\n","\n","# Predict for the next 30 days\n","future_days = 30\n","future_predictions = []\n","\n","for i in range(future_days):\n","    # Reshape the data for LSTM prediction\n","    X_input = np.array(last_n_days_scaled[-time_step:]).reshape(1, time_step, 1)\n","\n","    # Predict the next value\n","    predicted_value = model.predict(X_input)\n","\n","    # Store the predicted value\n","    future_predictions.append(predicted_value[0, 0])\n","\n","    # Append the predicted value to last_n_days_scaled for further predictions\n","    last_n_days_scaled = np.append(last_n_days_scaled, predicted_value).reshape(-1, 1)\n","    last_n_days_scaled = last_n_days_scaled[-time_step:]  # Keep the last 60 days\n","\n","# Inverse transform the predictions back to the original scale\n","future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n","\n","# Create a date range for the future predictions\n","last_date = data.index[-1]\n","future_dates = pd.date_range(last_date, periods=future_days + 1, freq='B')[1:]  # Skip the first to avoid repeating the last date\n","\n","# Create a DataFrame for future predictions\n","future_df = pd.DataFrame(future_predictions, index=future_dates, columns=['Predicted Close'])\n","\n","# Plot the historical data along with the future predictions\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(16,8))\n","plt.plot(data['Close'], label=\"Historical Prices\")\n","plt.plot(future_df['Predicted Close'], label=\"Future Predictions\", color='red')\n","plt.title(\"Stock Price Prediction for Next 30 Days\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Stock Price\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"BBvEq79ftBSI","executionInfo":{"status":"error","timestamp":1726921812019,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pranav Bhavsar","userId":"03342781595821087385"}},"outputId":"d6d00927-2a1b-409e-90cd-46ab683893f1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-a50023acffea>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use the 'Close' column for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclose_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Scale the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"cell_type":"code","source":["pip install tensorflow\n"],"metadata":{"id":"dsxL4YGKt9o-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","\n","# Use the 'Close' column for prediction\n","close_data = data['Close'].values.reshape(-1, 1)\n","\n","# Scale the data\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_data = scaler.fit_transform(close_data)\n","\n","# Split the data into training and testing sets (80% training)\n","training_data_len = int(np.ceil(len(scaled_data) * 0.8))\n","train_data = scaled_data[0:training_data_len, :]\n","\n","# Create the training dataset\n","def create_dataset(data, time_step=60):\n","    X, y = [], []\n","    for i in range(time_step, len(data)):\n","        X.append(data[i-time_step:i, 0])\n","        y.append(data[i, 0])\n","    return np.array(X), np.array(y)\n","\n","# Create the X_train and y_train datasets\n","time_step = 60\n","X_train, y_train = create_dataset(train_data, time_step)\n","\n","# Reshape the X_train data for the LSTM model\n","X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","\n","# Now I'll proceed to build and train the LSTM model.\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n","model.add(LSTM(units=50, return_sequences=False))\n","model.add(Dense(units=25))\n","model.add(Dense(units=1))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","model.fit(X_train, y_train, batch_size=64, epochs=10)\n","\n","# Use the trained model for future predictions\n","# Prepare the test dataset (last 60 time steps) for future predictions\n","last_n_days_scaled = scaled_data[-time_step:]\n","\n","# Predict for the next 30 days\n","future_days = 30\n","future_predictions = []\n","\n","for i in range(future_days):\n","    # Reshape the data for LSTM prediction\n","    X_input = np.array(last_n_days_scaled[-time_step:]).reshape(1, time_step, 1)\n","\n","    # Predict the next value\n","    predicted_value = model.predict(X_input)\n","\n","    # Store the predicted value\n","    future_predictions.append(predicted_value[0, 0])\n","\n","    # Append the predicted value to last_n_days_scaled for further predictions\n","    last_n_days_scaled = np.append(last_n_days_scaled, predicted_value).reshape(-1, 1)\n","    last_n_days_scaled = last_n_days_scaled[-time_step:]  # Keep the last 60 days\n","\n","# Inverse transform the predictions back to the original scale\n","future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n","\n","# Create a date range for the future predictions\n","last_date = data.index[-1]\n","future_dates = pd.date_range(last_date, periods=future_days + 1, freq='B')[1:]  # Skip the first to avoid repeating the last date\n","\n","# Create a DataFrame for future predictions\n","future_df = pd.DataFrame(future_predictions, index=future_dates, columns=['Predicted Close'])\n","\n","# Plot the historical data along with the future predictions\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(16,8))\n","plt.plot(data['Close'], label=\"Historical Prices\")\n","plt.plot(future_df['Predicted Close'], label=\"Future Predictions\", color='red')\n","plt.title(\"Stock Price Prediction for Next 30 Days\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Stock Price\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"_kJJ312duAlg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"HPwRSfYct9c0"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n"],"metadata":{"id":"6RDbPhSrukY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n","model.add(LSTM(units=50, return_sequences=False))\n","model.add(Dense(units=25))\n","model.add(Dense(units=1))\n"],"metadata":{"id":"OyjkrafWumKS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='mean_squared_error')\n"],"metadata":{"id":"XL66YMe9upKq","executionInfo":{"status":"error","timestamp":1726921812790,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pranav Bhavsar","userId":"03342781595821087385"}},"outputId":"bfc7674b-6ece-4a81-acfd-3089662730bc","colab":{"base_uri":"https://localhost:8080/","height":141}},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a241582cbd6e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["model.fit(X_train, y_train, batch_size=64, epochs=10)\n"],"metadata":{"id":"cJVm0nyVuq1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Number of days to predict in the future\n","future_days = 30\n","\n","# Use the last 60 time steps from the dataset for future predictions\n","last_n_days_scaled = scaled_data[-60:]  # Last 60 days from the training data\n","\n","future_predictions = []\n","\n","for i in range(future_days):\n","    # Prepare the input data for prediction (reshape to match LSTM input)\n","    X_input = np.array(last_n_days_scaled[-60:]).reshape(1, 60, 1)\n","\n","    # Predict the next value\n","    predicted_value = model.predict(X_input)\n","\n","    # Append the predicted value to the list of future predictions\n","    future_predictions.append(predicted_value[0, 0])\n","\n","    # Add the predicted value to the input sequence for the next prediction\n","    last_n_days_scaled = np.append(last_n_days_scaled, predicted_value).reshape(-1, 1)\n","    last_n_days_scaled = last_n_days_scaled[-60:]  # Keep the last 60 time steps\n"],"metadata":{"id":"xu7-euilu2jk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["future_predictions = scaler.inverse_transform(np.array(future_predictions).reshape(-1, 1))\n"],"metadata":{"id":"CCbWNes3u5no"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Create future dates for plotting (30 business days)\n","last_date = data.index[-1]\n","future_dates = pd.date_range(last_date, periods=future_days + 1, freq='B')[1:]\n","\n","# Create a DataFrame for future predictions\n","future_df = pd.DataFrame(future_predictions, index=future_dates, columns=['Predicted Close'])\n","\n","# Plot the historical data and future predictions\n","plt.figure(figsize=(16, 8))\n","plt.plot(data['Close'], label='Historical Prices')\n","plt.plot(future_df['Predicted Close'], label='Future Predictions', color='red')\n","plt.title('Stock Price Prediction for the Next 30 Days')\n","plt.xlabel('Date')\n","plt.ylabel('Stock Price')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"e-2Voda2u9mM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"First few rows of the dataset:\")\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"MM8KgMCZvGpt","executionInfo":{"status":"error","timestamp":1726921813554,"user_tz":-330,"elapsed":9,"user":{"displayName":"Pranav Bhavsar","userId":"03342781595821087385"}},"outputId":"864e663a-96b3-4f58-9322-4cb88f436a05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First few rows of the dataset:\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b69d4c3612eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First few rows of the dataset:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"cell_type":"markdown","source":["# TRYING SINGLE RNN"],"metadata":{"id":"WElhxUgatDfX"}},{"cell_type":"code","source":["def mean_absolute_percent_error(y_true,y_pred):\n","    total = np.sum(np.divide(np.array(y_pred),np.array(y_true)))\n","    return 100*np.abs((len(y_true))-total)/len(y_true)"],"metadata":{"id":"AiFn1T3FtK16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(8,1, figsize=(18,12))\n","i=1\n","for stock in stock_list:\n","    plt.subplot(3,2,i)\n","    df[stock].plot(label=stock)\n","    plt.xlabel('Time')\n","    plt.ylabel(stock)\n","    plt.title(stock+' vs time')\n","    plt.legend()\n","    i = i+1\n","plt.subplots_adjust(hspace=0.4)"],"metadata":{"id":"DFJyxER_tOdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"60GKhfzVtpm3"},"execution_count":null,"outputs":[]}]}