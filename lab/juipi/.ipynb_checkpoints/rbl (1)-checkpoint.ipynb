{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CjmR2T7_mZ4"
   },
   "source": [
    "# FLOW\n",
    "Here's the updated project flow incorporating your plan to analyze indicators one at a time and in combinations:\n",
    "\n",
    "1. **Data Acquisition:**\n",
    "   - Fetch Nifty 50 data from Yahoo Finance for the period 2014-2024.\n",
    "   - Clean and preprocess the data.\n",
    "   - **Output:** Cleaned dataset.\n",
    "\n",
    "2. **Feature Engineering (Indicators):**\n",
    "   - **Leading Indicators:**\n",
    "     - Start with the first leading indicator (e.g., RSI).\n",
    "     - Apply it to the dataset.\n",
    "     - Train LSTM, GRU, and RNN models using the dataset with this indicator.\n",
    "     - **Output:** Trained models and performance metrics.\n",
    "\n",
    "   - **Lagging Indicators:**\n",
    "     - Start with the first lagging indicator (e.g., SMA).\n",
    "     - Apply it to the dataset.\n",
    "     - Train LSTM, GRU, and RNN models using the dataset with this indicator.\n",
    "     - **Output:** Trained models and performance metrics.\n",
    "\n",
    "3. **Combining Indicators:**\n",
    "   - **Single Leading and Lagging Indicator:**\n",
    "     - Combine the first leading indicator (e.g., RSI) and the first lagging indicator (e.g., SMA).\n",
    "     - Train models using this combined dataset.\n",
    "     - **Output:** Trained models and performance metrics.\n",
    "\n",
    "   - **First Leading and Second Leading Indicator:**\n",
    "     - Add the second leading indicator (e.g., MACD) to the first leading indicator dataset.\n",
    "     - Train models using this new dataset.\n",
    "     - **Output:** Trained models and performance metrics.\n",
    "\n",
    "   - **First Lagging and Second Lagging Indicator:**\n",
    "     - Add the second lagging indicator (e.g., EMA) to the first lagging indicator dataset.\n",
    "     - Train models using this new dataset.\n",
    "     - **Output:** Trained models and performance metrics.\n",
    "\n",
    "   - **Combining Leading and Lagging Indicators:**\n",
    "     - Combine the first leading indicator and the second lagging indicator.\n",
    "     - Train models using this combined dataset.\n",
    "     - **Output:** Trained models and performance metrics.\n",
    "\n",
    "4. **Evaluation and Prediction:**\n",
    "   - Evaluate all trained models on the testing dataset.\n",
    "   - Compare the performance of each combination.\n",
    "   - Use the best-performing models to make predictions on unseen data.\n",
    "   - **Output:** Performance metrics and predicted values.\n",
    "\n",
    "5. **Backtesting:**\n",
    "   - Simulate trading strategies based on the best predictions.\n",
    "   - Analyze the performance of these strategies.\n",
    "   - **Output:** Backtest results.\n",
    "\n",
    "6. **Model Saving:**\n",
    "   - Save the final models and exported results.\n",
    "   - **Output:** Saved model files and results.\n",
    "\n",
    "7. **Final Output:**\n",
    "   - Visualize the comparison between predicted and actual values.\n",
    "   - Save the complete notebook and results.\n",
    "\n",
    "This structure allows for a systematic approach to testing each indicator and their combinations while evaluating their impact on model performance. Let me know if you need any more adjustments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLoAGCpz_LGE",
    "outputId": "16207aa7-999e-4260-fdd4-f2c432cbc578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\prana\\anaconda3\\lib\\site-packages (0.2.43)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (2.32.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (3.17.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\prana\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2Ws3orDAONi",
    "outputId": "b2cb3e31-935f-4ad7-b8fd-06d45aaeaf82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2014-01-02  6301.250000  6358.299805  6211.299805  6221.149902  6221.149902   \n",
      "2014-01-03  6194.549805  6221.700195  6171.250000  6211.149902  6211.149902   \n",
      "2014-01-06  6220.850098  6224.700195  6170.250000  6191.450195  6191.450195   \n",
      "2014-01-07  6203.899902  6221.500000  6144.750000  6162.250000  6162.250000   \n",
      "2014-01-08  6178.049805  6192.100098  6160.350098  6174.600098  6174.600098   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "2014-01-02  158100  \n",
      "2014-01-03  139000  \n",
      "2014-01-06  118300  \n",
      "2014-01-07  138600  \n",
      "2014-01-08  146900  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol for Nifty 50\n",
    "ticker = \"^NSEI\"  # Nifty 50 Index\n",
    "\n",
    "# Set the date range (e.g., last 5 years)\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "# Fetch the data\n",
    "nifty_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(nifty_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-rUxdCGxAPKD"
   },
   "outputs": [],
   "source": [
    "# Save the data to a CSV file\n",
    "nifty_data.to_csv('Untitled Folder/NSE50.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8cPWmzqABEjy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r41CNScHBInA",
    "outputId": "2fe6c764-8563-43b6-f15d-f71a67bd38e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2014-01-02  6301.250000  6358.299805  6211.299805  6221.149902  6221.149902   \n",
      "2014-01-03  6194.549805  6221.700195  6171.250000  6211.149902  6211.149902   \n",
      "2014-01-06  6220.850098  6224.700195  6170.250000  6191.450195  6191.450195   \n",
      "2014-01-07  6203.899902  6221.500000  6144.750000  6162.250000  6162.250000   \n",
      "2014-01-08  6178.049805  6192.100098  6160.350098  6174.600098  6174.600098   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "2014-01-02  158100  \n",
      "2014-01-03  139000  \n",
      "2014-01-06  118300  \n",
      "2014-01-07  138600  \n",
      "2014-01-08  146900  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('Untitled Folder/NSE50.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1mENRUfBJ6r",
    "outputId": "71cef3d3-edf1-4878-e724-36d8575b0638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2zajZkCWBLld"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns (if needed)\n",
    "data = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "IYjnB-86BNUY"
   },
   "outputs": [],
   "source": [
    "# Sort the data by date (if not already sorted)\n",
    "data.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "LZbA9JEGBQJc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the data (example for closing prices)\n",
    "scaled_data = scaler.fit_transform(data[['Close']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "vPbVX-15BRlP"
   },
   "outputs": [],
   "source": [
    "# Save the preprocessed data\n",
    "data.to_csv('Untitled Folder/NSE50_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxndBvJhBvhm"
   },
   "source": [
    "**STEP 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwzrPQP7CHcZ"
   },
   "source": [
    "## MACD (Moving Average Convergence Divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDw3bHNABTYx",
    "outputId": "e193936e-5ac0-433c-9dd8-a09637ddaf17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Close      MACD  Signal_Line\n",
      "0  6221.149902  0.000000     0.000000\n",
      "1  6211.149902 -0.797721    -0.159544\n",
      "2  6191.450195 -2.985111    -0.724658\n",
      "3  6162.250000 -6.994221    -1.978570\n",
      "4  6174.600098 -9.070362    -3.396929\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Untitled Folder/NSE50_processed.csv')\n",
    "\n",
    "# Calculate MACD\n",
    "def calculate_macd(df, short_window=12, long_window=26, signal_window=9):\n",
    "    # Calculate the short-term exponential moving average (EMA)\n",
    "    df['EMA12'] = df['Close'].ewm(span=short_window, adjust=False).mean()\n",
    "    # Calculate the long-term EMA\n",
    "    df['EMA26'] = df['Close'].ewm(span=long_window, adjust=False).mean()\n",
    "    # Calculate MACD\n",
    "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "    # Calculate Signal Line\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the MACD calculation\n",
    "data_with_macd = calculate_macd(data)\n",
    "\n",
    "# Display the first few rows of the modified dataset\n",
    "print(data_with_macd[['Close', 'MACD', 'Signal_Line']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7mU7I7fCQ2z",
    "outputId": "c13a040c-9ed6-46d3-bf1b-64df9172f104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Untitled Folder/NSE50_with_MACD.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the modified dataset to a new CSV file\n",
    "output_file_path = 'Untitled Folder/NSE50_with_MACD.csv'\n",
    "data_with_macd.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgMWTLXvCo7A"
   },
   "source": [
    "## data prepareation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XCweiVRyCcWD",
    "outputId": "2ea6ffac-8a7c-43d9-ab7a-f3fd5ce293df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1913, 60, 6), (1913,)\n",
      "Testing data shape: (479, 60, 6), (479,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the MACD dataset\n",
    "data = pd.read_csv('Untitled Folder/NSE50_with_MACD.csv')\n",
    "\n",
    "# Select relevant features (OHLC and MACD)\n",
    "features = data[['Open', 'High', 'Low', 'Close', 'MACD', 'Signal_Line']].values\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "\n",
    "# Function to create sequences for LSTM/GRU input\n",
    "def create_sequences(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        a = data[i:(i + time_step), :]  # Previous time steps\n",
    "        X.append(a)\n",
    "        y.append(data[i + time_step, 3])  # Target is the 'Close' price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences (e.g., using 60 time steps)\n",
    "time_step = 60\n",
    "X, y = create_sequences(scaled_data, time_step)\n",
    "\n",
    "# Split into training and testing sets (e.g., 80% training, 20% testing)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}, {y_train.shape}')\n",
    "print(f'Testing data shape: {X_test.shape}, {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxpNwKibCz9N"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOnoHbhMCq1v",
    "outputId": "de98e585-a784-4f66-84ec-8f1ba4202a55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 0.0329 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 8.0005e-04 - val_loss: 0.0011\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 5.9712e-04 - val_loss: 6.8466e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 5.6680e-04 - val_loss: 9.3438e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 4.7108e-04 - val_loss: 8.2671e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 4.7209e-04 - val_loss: 5.4583e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 4.5500e-04 - val_loss: 5.9279e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.9328e-04 - val_loss: 5.0495e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 4.0855e-04 - val_loss: 5.5189e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 4.0640e-04 - val_loss: 8.4892e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.3977e-04 - val_loss: 4.9542e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3.6513e-04 - val_loss: 4.7086e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.3377e-04 - val_loss: 4.6046e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.1443e-04 - val_loss: 4.9406e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.2870e-04 - val_loss: 5.2927e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.3140e-04 - val_loss: 4.6133e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 3.0736e-04 - val_loss: 4.7586e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3.5217e-04 - val_loss: 5.2381e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3.2310e-04 - val_loss: 4.3143e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 2.8631e-04 - val_loss: 4.2829e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.0758e-04 - val_loss: 5.5026e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.1034e-04 - val_loss: 5.3318e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 2.8086e-04 - val_loss: 6.3435e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 2.9013e-04 - val_loss: 3.9602e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 3.2780e-04 - val_loss: 5.3520e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 3.1256e-04 - val_loss: 4.3159e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 2.5579e-04 - val_loss: 8.3737e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 2.6521e-04 - val_loss: 4.8419e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.3788e-04 - val_loss: 0.0018\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 3.0794e-04 - val_loss: 5.5921e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.1414e-04 - val_loss: 4.5198e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.7131e-04 - val_loss: 5.9406e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 2.2992e-04 - val_loss: 4.7172e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 2.4114e-04 - val_loss: 6.4682e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 2.3558e-04 - val_loss: 3.4401e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 2.2267e-04 - val_loss: 4.8989e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 2.5812e-04 - val_loss: 8.8782e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 2.5449e-04 - val_loss: 4.4052e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 2.0575e-04 - val_loss: 4.3038e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 1.9704e-04 - val_loss: 7.0021e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 2.1218e-04 - val_loss: 8.6524e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 2.1882e-04 - val_loss: 4.3146e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 2.6434e-04 - val_loss: 3.6256e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 2.1020e-04 - val_loss: 5.5173e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 1.9965e-04 - val_loss: 6.1994e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 2.0276e-04 - val_loss: 0.0013\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 2.0035e-04 - val_loss: 4.6059e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 2.3917e-04 - val_loss: 5.5403e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 1.8850e-04 - val_loss: 5.9689e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 1.8257e-04 - val_loss: 4.5890e-04\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - loss: 0.0141 - val_loss: 3.7745e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 7.5685e-04 - val_loss: 5.8533e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 5.9969e-04 - val_loss: 4.2654e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 4.0051e-04 - val_loss: 3.1959e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 3.5310e-04 - val_loss: 5.7977e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 3.6792e-04 - val_loss: 3.7683e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 3.1754e-04 - val_loss: 2.8380e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 2.7841e-04 - val_loss: 2.8851e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 2.9870e-04 - val_loss: 3.7872e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 3.0575e-04 - val_loss: 3.0640e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 2.6791e-04 - val_loss: 2.7462e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 2.5255e-04 - val_loss: 2.7670e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 2.5590e-04 - val_loss: 3.2315e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 2.3836e-04 - val_loss: 3.0350e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 3.4310e-04 - val_loss: 2.7165e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 2.1205e-04 - val_loss: 2.8977e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 1.9506e-04 - val_loss: 2.9574e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 2.5883e-04 - val_loss: 3.5921e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 2.4648e-04 - val_loss: 6.5628e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 2.0455e-04 - val_loss: 3.4849e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 2.0830e-04 - val_loss: 2.6119e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 1.8917e-04 - val_loss: 2.5458e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - loss: 1.7368e-04 - val_loss: 3.2459e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 1.6360e-04 - val_loss: 2.9794e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 1.7080e-04 - val_loss: 2.8176e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 2.0234e-04 - val_loss: 2.4628e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 1.6573e-04 - val_loss: 2.5256e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 1.4361e-04 - val_loss: 2.5102e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 1.5594e-04 - val_loss: 3.3767e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 1.7758e-04 - val_loss: 2.4332e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 1.7729e-04 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 1.6652e-04 - val_loss: 2.5935e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 1.4212e-04 - val_loss: 4.0309e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 1.4274e-04 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 1.7096e-04 - val_loss: 3.0889e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 1.3248e-04 - val_loss: 4.4719e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 1.6125e-04 - val_loss: 2.5131e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 1.2962e-04 - val_loss: 2.7121e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 1.3634e-04 - val_loss: 6.9326e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 1.3109e-04 - val_loss: 9.4337e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - loss: 1.5980e-04 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 1.3797e-04 - val_loss: 3.1827e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 1.7911e-04 - val_loss: 2.7081e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 1.4235e-04 - val_loss: 7.4167e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 1.1765e-04 - val_loss: 4.5126e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 1.2900e-04 - val_loss: 3.2541e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 1.1537e-04 - val_loss: 3.1874e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 1.2957e-04 - val_loss: 3.0309e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - loss: 1.6781e-04 - val_loss: 6.1231e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 1.4891e-04 - val_loss: 2.5098e-04\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.0909 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.8073e-04 - val_loss: 0.0012\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.5326e-04 - val_loss: 8.0029e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 7.5949e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.1707e-04 - val_loss: 0.0012\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.9696e-04 - val_loss: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.9400e-04 - val_loss: 6.4048e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.2336e-04 - val_loss: 6.4898e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.5039e-04 - val_loss: 8.9120e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.7709e-04 - val_loss: 8.3808e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.0562e-04 - val_loss: 5.3043e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.5584e-04 - val_loss: 9.2578e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9339e-04 - val_loss: 6.4157e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.9869e-04 - val_loss: 5.1984e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.3703e-04 - val_loss: 4.6477e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.8042e-04 - val_loss: 6.6469e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.9406e-04 - val_loss: 9.8749e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.2691e-04 - val_loss: 6.2527e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.9847e-04 - val_loss: 5.0001e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.5655e-04 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.9198e-04 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.6639e-04 - val_loss: 8.3952e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.0932e-04 - val_loss: 8.7110e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.2921e-04 - val_loss: 5.9173e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.8288e-04 - val_loss: 6.1379e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.3385e-04 - val_loss: 6.7931e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.9685e-04 - val_loss: 4.6957e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.5613e-04 - val_loss: 7.5847e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.7958e-04 - val_loss: 5.4435e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 4.1388e-04 - val_loss: 6.1850e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.3594e-04 - val_loss: 6.0016e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.7666e-04 - val_loss: 4.8044e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.5811e-04 - val_loss: 5.2970e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.1377e-04 - val_loss: 4.8406e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.3957e-04 - val_loss: 5.9057e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9492e-04 - val_loss: 4.6928e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.2570e-04 - val_loss: 7.2720e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.3902e-04 - val_loss: 8.2308e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.7149e-04 - val_loss: 6.1916e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.3287e-04 - val_loss: 5.5620e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.7326e-04 - val_loss: 5.3017e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.7978e-04 - val_loss: 6.3181e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.0259e-04 - val_loss: 5.3390e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.8694e-04 - val_loss: 0.0016\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.0694e-04 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "\n",
    "# Function to build and train the model\n",
    "def build_and_train_model(model_type, X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "\n",
    "    if model_type == 'LSTM':\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "    elif model_type == 'GRU':\n",
    "        model.add(GRU(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(GRU(50, return_sequences=False))\n",
    "\n",
    "    elif model_type == 'RNN':\n",
    "        model.add(tf.keras.layers.SimpleRNN(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(tf.keras.layers.SimpleRNN(50, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build and train models\n",
    "lstm_model = build_and_train_model('LSTM', X_train, y_train, X_test, y_test)\n",
    "gru_model = build_and_train_model('GRU', X_train, y_train, X_test, y_test)\n",
    "rnn_model = build_and_train_model('RNN', X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnbtd3CADjIL"
   },
   "source": [
    "## **Evaluation and Prediction Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d39ZT-PC1Pa",
    "outputId": "68aa32f2-b500-4e81-e982-2cdbf3d717f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "LSTM - MSE: 728.4030028558212 MAE: 20.71108728560268\n",
      "GRU - MSE: 398.37664365203756 MAE: 15.268548273862189\n",
      "RNN - MSE: 2026.3291042497028 MAE: 38.97001646272547\n"
     ]
    }
   ],
   "source": [
    "# Function to make predictions and evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform to get actual values\n",
    "    y_pred_inv = scaler.inverse_transform(np.concatenate((np.zeros((y_pred.shape[0], 5)), y_pred), axis=1))[:, -1]\n",
    "    y_test_inv = scaler.inverse_transform(np.concatenate((np.zeros((y_test.shape[0], 5)), y_test.reshape(-1, 1)), axis=1))[:, -1]\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mse = np.mean((y_test_inv - y_pred_inv) ** 2)\n",
    "    mae = np.mean(np.abs(y_test_inv - y_pred_inv))\n",
    "\n",
    "    return y_pred_inv, y_test_inv, mse, mae\n",
    "\n",
    "# Evaluate each model\n",
    "lstm_preds, lstm_actuals, lstm_mse, lstm_mae = evaluate_model(lstm_model, X_test, y_test)\n",
    "gru_preds, gru_actuals, gru_mse, gru_mae = evaluate_model(gru_model, X_test, y_test)\n",
    "rnn_preds, rnn_actuals, rnn_mse, rnn_mae = evaluate_model(rnn_model, X_test, y_test)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"LSTM - MSE:\", lstm_mse, \"MAE:\", lstm_mae)\n",
    "print(\"GRU - MSE:\", gru_mse, \"MAE:\", gru_mae)\n",
    "print(\"RNN - MSE:\", rnn_mse, \"MAE:\", rnn_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0PXuXj3DwyG"
   },
   "source": [
    "#### macd results\n",
    "LSTM - MSE: 920.6475950544653 MAE: 24.509143158454638\n",
    "GRU - MSE: 2367.4551505404006 MAE: 43.65844915543832\n",
    "RNN - MSE: 1467.7172675407917 MAE: 30.45649810099187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u3GMKWAEPXW"
   },
   "source": [
    "### hypertuning the macd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8RJZEvBDm9_",
    "outputId": "8ecb2586-0f26-456e-93e8-93dccc117517"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'units_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Loop over hyperparameters\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m units \u001b[38;5;129;01min\u001b[39;00m units_list:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dropout \u001b[38;5;129;01min\u001b[39;00m dropout_rates:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m units and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dropout rate...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'units_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Modify the model compilation to include metrics\n",
    "def create_model(units=50, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Add MAE as a metric\n",
    "    return model\n",
    "\n",
    "# Loop over hyperparameters\n",
    "for units in units_list:\n",
    "    for dropout in dropout_rates:\n",
    "        print(f'Training model with {units} units and {dropout} dropout rate...')\n",
    "        model = create_model(units, dropout)\n",
    "\n",
    "        # Use early stopping to prevent overfitting\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
    "                  callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "        # Evaluate the model\n",
    "        loss, mae = model.evaluate(X_test, y_test, verbose=0)  # Only loss and MAE are returned\n",
    "        mse = loss  # Since we're only using MSE as the loss\n",
    "        results.append((units, dropout, mse, mae))\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results, columns=['Units', 'Dropout Rate', 'MSE', 'MAE'])\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9_oS9zPIVxp"
   },
   "source": [
    "### results of the macd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qm-7J3RlE0Yt",
    "outputId": "4c3b34d4-4da5-43e2-b89b-1994f32dae69"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'early_stopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m best_model \u001b[38;5;241m=\u001b[39m create_model(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the model again on the training data (you may choose to load the best weights instead)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m----> 8\u001b[0m                callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m best_model_predictions \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'early_stopping' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the best model (150 units, 0.2 dropout) for predictions\n",
    "best_model = create_model(units=150, dropout_rate=0.2)\n",
    "\n",
    "# Fit the model again on the training data (you may choose to load the best weights instead)\n",
    "best_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
    "               callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "best_model_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "best_model_predictions_inv = scaler.inverse_transform(np.concatenate((np.zeros((best_model_predictions.shape[0], 5)), best_model_predictions), axis=1))[:, -1]\n",
    "y_test_inv = scaler.inverse_transform(np.concatenate((np.zeros((y_test.shape[0], 5)), y_test.reshape(-1, 1)), axis=1))[:, -1]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue')\n",
    "plt.plot(best_model_predictions_inv, label='Predicted Prices', color='orange')\n",
    "plt.title('Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "id": "VjwjiA1aGOE5",
    "outputId": "60b1a521-e92f-49f8-adf0-32631a5f0378"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'early_stopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create and train the LSTM model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m create_model(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      3\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m----> 4\u001b[0m                callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Make predictions with LSTM\u001b[39;00m\n\u001b[0;32m      7\u001b[0m lstm_predictions \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'early_stopping' is not defined"
     ]
    }
   ],
   "source": [
    "# Create and train the LSTM model\n",
    "lstm_model = create_model(units=150, dropout_rate=0.2)\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
    "               callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Make predictions with LSTM\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "lstm_predictions_inv = scaler.inverse_transform(np.concatenate((np.zeros((lstm_predictions.shape[0], 5)), lstm_predictions), axis=1))[:, -1]\n",
    "y_test_inv = scaler.inverse_transform(np.concatenate((np.zeros((y_test.shape[0], 5)), y_test.reshape(-1, 1)), axis=1))[:, -1]\n",
    "\n",
    "# Plot the LSTM results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue', alpha=0.5)\n",
    "plt.plot(lstm_predictions_inv, label='LSTM Predicted Prices', color='orange', alpha=0.7)\n",
    "plt.title('LSTM: Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1JpK_wJRGskL",
    "outputId": "79bc6d55-9bf9-4f65-a454-af32fee0eabc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'early_stopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m gru_model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m gru_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m gru_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m---> 10\u001b[0m               callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions with GRU\u001b[39;00m\n\u001b[0;32m     13\u001b[0m gru_predictions \u001b[38;5;241m=\u001b[39m gru_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'early_stopping' is not defined"
     ]
    }
   ],
   "source": [
    "# Create and train the GRU model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(150, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(GRU(150, return_sequences=False))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(Dense(1))\n",
    "gru_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "gru_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
    "              callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Make predictions with GRU\n",
    "gru_predictions = gru_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "gru_predictions_inv = scaler.inverse_transform(np.concatenate((np.zeros((gru_predictions.shape[0], 5)), gru_predictions), axis=1))[:, -1]\n",
    "\n",
    "# Plot the GRU results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue', alpha=0.5)\n",
    "plt.plot(gru_predictions_inv, label='GRU Predicted Prices', color='green', alpha=0.7)\n",
    "plt.title('GRU: Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nAjnbkvHst6",
    "outputId": "e2995940-43da-4de5-fa66-b8b198bd5c1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the LSTM model\n",
    "lstm_model.save('lstm_model_macd.h5')\n",
    "\n",
    "# Save the GRU model\n",
    "gru_model.save('gru_model_macd.h5')\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3P1aN_TIanr"
   },
   "source": [
    "## **MA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "kgumIuP0IQn0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the processed data\n",
    "data_path = 'Untitled Folder/NSE50_processed.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Calculate Moving Averages\n",
    "# For example, calculate 20-day and 50-day SMAs\n",
    "data['SMA_20'] = data['Close'].rolling(window=20).mean()\n",
    "data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "\n",
    "# Calculate Exponential Moving Average (EMA)\n",
    "data['EMA_20'] = data['Close'].ewm(span=20, adjust=False).mean()\n",
    "data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()\n",
    "\n",
    "# Drop rows with NaN values caused by rolling calculations\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Save the updated dataset\n",
    "data.to_csv('Untitled Folder/NSE50_with_moving_averages.csv', index=False)\n",
    "\n",
    "# Prepare data for training (similar to previous steps)\n",
    "# Feature selection: Include moving averages\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_20', 'SMA_50', 'EMA_20', 'EMA_50']\n",
    "X = data[features].values\n",
    "y = data['Close'].values\n",
    "\n",
    "# Continue with the same preprocessing steps for LSTM, GRU, RNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create sequences (similar to before)\n",
    "def create_sequences(X, y, time_steps=60):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i + time_steps])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train_seq, y_train_seq = create_sequences(X_train, y_train)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test, y_test)\n",
    "\n",
    "# Train your models (LSTM, GRU, RNN) with the updated dataset\n",
    "# You can reuse the previous model training code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7FALijCCImpq",
    "outputId": "e3383e9b-03c0-49d1-b9ef-54af5e5cb909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date          Open          High           Low         Close  \\\n",
      "2448  2023-12-22  21295.849609  21390.500000  21232.449219  21349.400391   \n",
      "2449  2023-12-26  21365.199219  21477.150391  21329.449219  21441.349609   \n",
      "2450  2023-12-27  21497.650391  21675.750000  21495.800781  21654.750000   \n",
      "2451  2023-12-28  21715.000000  21801.449219  21678.000000  21778.699219   \n",
      "2452  2023-12-29  21737.650391  21770.300781  21676.900391  21731.400391   \n",
      "\n",
      "      Volume        SMA_20        SMA_50        EMA_20        EMA_50  \n",
      "2448  284700  20831.387500  20020.751992  20860.984922  20298.886262  \n",
      "2449  219500  20913.720020  20053.351992  20916.257749  20343.688746  \n",
      "2450  256500  21001.972559  20090.566992  20986.590345  20395.102913  \n",
      "2451  393100  21086.077539  20131.119961  21062.029285  20449.361591  \n",
      "2452  270900  21165.990039  20171.112969  21125.778914  20499.637623  \n"
     ]
    }
   ],
   "source": [
    "# Check the updated dataframe\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKBzd1r_JJpH"
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjdSBGxcI2zb",
    "outputId": "5bc7b902-efcf-48b3-d8cb-0d6c5e939465"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'early_stopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train the LSTM model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_train_seq, y_train_seq, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_seq, y_test_seq),\n\u001b[1;32m---> 15\u001b[0m                callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'early_stopping' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(150, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(LSTM(150, return_sequences=False))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, validation_data=(X_test_seq, y_test_seq),\n",
    "               callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikSC_ak4JLsS",
    "outputId": "f7601a2f-ecf9-4221-879c-980d75c097d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'early_stopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m gru_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Train the GRU model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m gru_model\u001b[38;5;241m.\u001b[39mfit(X_train_seq, y_train_seq, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test_seq, y_test_seq),\n\u001b[1;32m---> 14\u001b[0m               callbacks\u001b[38;5;241m=\u001b[39m[early_stopping], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'early_stopping' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "# GRU Model\n",
    "gru_model = Sequential()\n",
    "gru_model.add(GRU(150, return_sequences=True, input_shape=(X_train_seq.shape[1], X_train_seq.shape[2])))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(GRU(150, return_sequences=False))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(Dense(1))\n",
    "gru_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the GRU model\n",
    "gru_model.fit(X_train_seq, y_train_seq, epochs=50, batch_size=32, validation_data=(X_test_seq, y_test_seq),\n",
    "              callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKfl0fSrJWeA",
    "outputId": "01250ea8-5d7f-42db-d575-30ecee82885b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM - MSE: 155491248.0, MAE: 11861.4619140625\n",
      "GRU - MSE: 155493488.0, MAE: 11861.5556640625\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LSTM Model\n",
    "lstm_mse, lstm_mae = lstm_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "print(f'LSTM - MSE: {lstm_mse}, MAE: {lstm_mae}')\n",
    "\n",
    "# Evaluate GRU Model\n",
    "gru_mse, gru_mae = gru_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "print(f'GRU - MSE: {gru_mse}, MAE: {gru_mae}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "mnKowxGaOpAg",
    "outputId": "c3345d5a-f3b2-42d2-9df7-4ee00dcdbd01"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_inv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Plot actual values\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(y_test_inv, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual Prices\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Plot LSTM predictions\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(lstm_predictions_inv, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM Predictions\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_inv' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the figure and axes\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot actual values\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue')\n",
    "\n",
    "# Plot LSTM predictions\n",
    "plt.plot(lstm_predictions_inv, label='LSTM Predictions', color='orange')\n",
    "\n",
    "# Plot GRU predictions\n",
    "plt.plot(gru_predictions_inv, label='GRU Predictions', color='green')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5vsImVKQra4",
    "outputId": "e9ccff89-861d-4c35-d216-e63c4a975701"
   },
   "outputs": [],
   "source": [
    "# Save the LSTM model\n",
    "lstm_model.save('lstm_model_ma.h5')\n",
    "\n",
    "# Save the GRU model\n",
    "gru_model.save('gru_model_ma.h5')\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUmU7ptBRMGI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EzXDnaLFQvOW",
    "outputId": "f6006fcd-4a7c-452c-df7e-e6ff44b6f5b8"
   },
   "outputs": [],
   "source": [
    "# prompt: save all the iamges of the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... (Your existing code) ...\n",
    "\n",
    "# Save the plot of actual vs predicted prices for the best LSTM model\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue')\n",
    "plt.plot(best_model_predictions_inv, label='Predicted Prices', color='orange')\n",
    "plt.title('Actual vs Predicted Closing Prices (Best LSTM Model)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('best_lstm_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "# Save the plot of actual vs predicted prices for the LSTM model\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue', alpha=0.5)\n",
    "plt.plot(lstm_predictions_inv, label='LSTM Predicted Prices', color='orange', alpha=0.7)\n",
    "plt.title('LSTM: Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('lstm_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the plot of actual vs predicted prices for the GRU model\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue', alpha=0.5)\n",
    "plt.plot(gru_predictions_inv, label='GRU Predicted Prices', color='green', alpha=0.7)\n",
    "plt.title('GRU: Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('gru_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "# Save the final combined plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue')\n",
    "plt.plot(lstm_predictions_inv, label='LSTM Predictions', color='orange')\n",
    "plt.plot(gru_predictions_inv, label='GRU Predictions', color='green')\n",
    "plt.title('Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('combined_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "print(\"Plots saved as PNG images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3BGixFYWSLqw",
    "outputId": "e346e3ff-71e0-4f8b-f249-59b82dca66c9"
   },
   "outputs": [],
   "source": [
    "# prompt: save the iamges of the out of the macd and the moving average with the name\n",
    "\n",
    "# Assuming you have already generated the plots as shown in your provided code.\n",
    "# The code to save the plots is already included in your original code:\n",
    "\n",
    "# ... (Your existing code) ...\n",
    "\n",
    "# Save the plot of actual vs predicted prices for the best LSTM model\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue')\n",
    "plt.plot(best_model_predictions_inv, label='Predicted Prices', color='orange')\n",
    "plt.title('Actual vs Predicted Closing Prices (Best LSTM Model)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('best_lstm_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "# Save the plot of actual vs predicted prices for the LSTM model\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue', alpha=0.5)\n",
    "plt.plot(lstm_predictions_inv, label='LSTM Predicted Prices', color='orange', alpha=0.7)\n",
    "plt.title('LSTM: Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('lstm_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the plot of actual vs predicted prices for the GRU model\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue', alpha=0.5)\n",
    "plt.plot(gru_predictions_inv, label='GRU Predicted Prices', color='green', alpha=0.7)\n",
    "plt.title('GRU: Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.savefig('gru_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "# Save the final combined plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(y_test_inv, label='Actual Prices', color='blue')\n",
    "plt.plot(lstm_predictions_inv, label='LSTM Predictions', color='orange')\n",
    "plt.plot(gru_predictions_inv, label='GRU Predictions', color='green')\n",
    "plt.title('Model Predictions vs Actual Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('combined_model_plot.png') # Save the plot as a PNG image\n",
    "plt.show()\n",
    "\n",
    "print(\"Plots saved as PNG images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqHiAkEASeav"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
