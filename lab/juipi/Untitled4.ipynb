{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223944a9-26fc-41b1-84c3-f52c730d1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed55eca-a24a-42ab-8c92-34d7049510f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('salaries.csv', delimiter = '\\t')\n",
    "data = data.apply(lambda x: x.str.replace('\\xa0', ' ') if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0bf59d-cf76-42ea-8183-cafcb904df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 9', axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e174c5c0-452f-4fde-89ae-686a0307eaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401190 entries, 0 to 401189\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   role            401190 non-null  object \n",
      " 1   country         401190 non-null  object \n",
      " 2   company         401185 non-null  object \n",
      " 3   company_rating  390055 non-null  float64\n",
      " 4   job_title       401190 non-null  object \n",
      " 5   median          401190 non-null  object \n",
      " 6   low             401190 non-null  object \n",
      " 7   high            401190 non-null  object \n",
      " 8   unit            401190 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 27.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa69445-34ef-44ee-acaf-69bb5526a56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>country</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_title</th>\n",
       "      <th>median</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>CTW</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>¥1,500,000</td>\n",
       "      <td>¥1M</td>\n",
       "      <td>¥18M</td>\n",
       "      <td>/ yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>FUJIFILM</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>¥5,000,000</td>\n",
       "      <td>¥5M</td>\n",
       "      <td>¥7M</td>\n",
       "      <td>/ yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>GMO Internet</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>¥6,500,000</td>\n",
       "      <td>¥7M</td>\n",
       "      <td>-</td>\n",
       "      <td>/ yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Data4Cʼs</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>¥350,000</td>\n",
       "      <td>¥300K</td>\n",
       "      <td>¥402K</td>\n",
       "      <td>/ mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>¥6,250,000</td>\n",
       "      <td>¥5M</td>\n",
       "      <td>¥8M</td>\n",
       "      <td>/ yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401185</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>FinProm</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>RON 3,716</td>\n",
       "      <td>RON 4K</td>\n",
       "      <td>RON 4K</td>\n",
       "      <td>/ mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401186</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>GRS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>RON 1,612</td>\n",
       "      <td>RON 2K</td>\n",
       "      <td>RON 2K</td>\n",
       "      <td>/ mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401187</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>Woods Valldata</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>RON 1,648</td>\n",
       "      <td>RON 2K</td>\n",
       "      <td>RON 2K</td>\n",
       "      <td>/ yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401188</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>FM Logistic</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>RON 4,908</td>\n",
       "      <td>RON 5K</td>\n",
       "      <td>RON 5K</td>\n",
       "      <td>/ mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401189</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>iCredit (Romania)</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>RON 1,001</td>\n",
       "      <td>RON 969</td>\n",
       "      <td>RON 1K</td>\n",
       "      <td>/ mo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401190 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  role  country            company  company_rating  \\\n",
       "0       Data Scientist    Japan                CTW             2.9   \n",
       "1       Data Scientist    Japan           FUJIFILM             3.7   \n",
       "2       Data Scientist    Japan       GMO Internet             3.3   \n",
       "3       Data Scientist    Japan           Data4Cʼs             3.0   \n",
       "4       Data Scientist    Japan           Deloitte             4.0   \n",
       "...                ...      ...                ...             ...   \n",
       "401185   Data Engineer  Romania            FinProm             2.9   \n",
       "401186   Data Engineer  Romania                GRS             3.0   \n",
       "401187   Data Engineer  Romania     Woods Valldata             2.6   \n",
       "401188   Data Engineer  Romania        FM Logistic             3.5   \n",
       "401189   Data Engineer  Romania  iCredit (Romania)             2.1   \n",
       "\n",
       "                  job_title      median      low    high   unit  \n",
       "0            Data Scientist  ¥1,500,000      ¥1M    ¥18M   / yr  \n",
       "1            Data Scientist  ¥5,000,000      ¥5M     ¥7M   / yr  \n",
       "2            Data Scientist  ¥6,500,000      ¥7M      -    / yr  \n",
       "3            Data Scientist    ¥350,000    ¥300K   ¥402K   / mo  \n",
       "4            Data Scientist  ¥6,250,000      ¥5M     ¥8M   / yr  \n",
       "...                     ...         ...      ...     ...    ...  \n",
       "401185  Data Entry Operator   RON 3,716   RON 4K  RON 4K   / mo  \n",
       "401186  Data Entry Operator   RON 1,612   RON 2K  RON 2K   / mo  \n",
       "401187  Data Entry Operator   RON 1,648   RON 2K  RON 2K   / yr  \n",
       "401188  Data Entry Operator   RON 4,908   RON 5K  RON 5K   / mo  \n",
       "401189  Data Entry Operator   RON 1,001  RON 969  RON 1K   / mo  \n",
       "\n",
       "[401190 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a6b1260-de0e-45d4-bfd6-911442eb4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_unit(unit):\n",
    "    if unit == ' / yr':\n",
    "        return 'yearly'\n",
    "    elif unit == ' / mo':\n",
    "        return 'monthly'\n",
    "    elif unit == ' / hr':\n",
    "        return 'hourly'\n",
    "data['unit'] = data['unit'].apply(change_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6695de-47f6-4139-885c-cd65576957ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(x):\n",
    "    units = x.split(' ')\n",
    "    if len(units) ==1:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return units[0]\n",
    "data['currency'] = data['median'].apply(get_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "520f47cf-2ea5-48f7-8335-b532a10f99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_salary(x):\n",
    "    x = str(x)\n",
    "    unit = get_currency(x)\n",
    "    x = x.replace(unit,'')\n",
    "    x = x.replace(',','')\n",
    "    x = x.replace('M','000000')\n",
    "    x = x.replace('K','000')\n",
    "    return x\n",
    "data['median'] = data['median'].apply(format_salary)\n",
    "data['low'] = data['low'].apply(format_salary)\n",
    "data['high'] = data['high'].apply(format_salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e96263f-39fd-49d1-a1cb-726c006df0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>country</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_title</th>\n",
       "      <th>median</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>unit</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>CTW</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1500000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>18000000</td>\n",
       "      <td>None</td>\n",
       "      <td>¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>FUJIFILM</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>5000000</td>\n",
       "      <td>5000000</td>\n",
       "      <td>7000000</td>\n",
       "      <td>None</td>\n",
       "      <td>¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>GMO Internet</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>6500000</td>\n",
       "      <td>7000000</td>\n",
       "      <td>-</td>\n",
       "      <td>None</td>\n",
       "      <td>¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Data4Cʼs</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>350000</td>\n",
       "      <td>300000</td>\n",
       "      <td>402000</td>\n",
       "      <td>None</td>\n",
       "      <td>¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>6250000</td>\n",
       "      <td>5000000</td>\n",
       "      <td>8000000</td>\n",
       "      <td>None</td>\n",
       "      <td>¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401185</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>FinProm</td>\n",
       "      <td>2.9</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>3716</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "      <td>None</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401186</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>GRS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>1612</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401187</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>Woods Valldata</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>1648</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401188</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>FM Logistic</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>4908</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>None</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401189</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Romania</td>\n",
       "      <td>iCredit (Romania)</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Data Entry Operator</td>\n",
       "      <td>1001</td>\n",
       "      <td>969</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>RON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401190 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  role  country            company  company_rating  \\\n",
       "0       Data Scientist    Japan                CTW             2.9   \n",
       "1       Data Scientist    Japan           FUJIFILM             3.7   \n",
       "2       Data Scientist    Japan       GMO Internet             3.3   \n",
       "3       Data Scientist    Japan           Data4Cʼs             3.0   \n",
       "4       Data Scientist    Japan           Deloitte             4.0   \n",
       "...                ...      ...                ...             ...   \n",
       "401185   Data Engineer  Romania            FinProm             2.9   \n",
       "401186   Data Engineer  Romania                GRS             3.0   \n",
       "401187   Data Engineer  Romania     Woods Valldata             2.6   \n",
       "401188   Data Engineer  Romania        FM Logistic             3.5   \n",
       "401189   Data Engineer  Romania  iCredit (Romania)             2.1   \n",
       "\n",
       "                  job_title   median      low      high  unit currency  \n",
       "0            Data Scientist  1500000  1000000  18000000  None        ¥  \n",
       "1            Data Scientist  5000000  5000000   7000000  None        ¥  \n",
       "2            Data Scientist  6500000  7000000        -   None        ¥  \n",
       "3            Data Scientist   350000   300000    402000  None        ¥  \n",
       "4            Data Scientist  6250000  5000000   8000000  None        ¥  \n",
       "...                     ...      ...      ...       ...   ...      ...  \n",
       "401185  Data Entry Operator     3716     4000      4000  None      RON  \n",
       "401186  Data Entry Operator     1612     2000      2000  None      RON  \n",
       "401187  Data Entry Operator     1648     2000      2000  None      RON  \n",
       "401188  Data Entry Operator     4908     5000      5000  None      RON  \n",
       "401189  Data Entry Operator     1001      969      1000  None      RON  \n",
       "\n",
       "[401190 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a1aeee-2d54-4baf-8268-8aa28fe30452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26976"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data['country']=='United States']['company'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "727e91da-1b11-4a06-990c-a15105f06245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             role country       company  company_rating       job_title  \\\n",
      "0  Data Scientist   Japan           CTW             2.9  Data Scientist   \n",
      "1  Data Scientist   Japan      FUJIFILM             3.7  Data Scientist   \n",
      "2  Data Scientist   Japan  GMO Internet             3.3  Data Scientist   \n",
      "3  Data Scientist   Japan      Data4Cʼs             3.0  Data Scientist   \n",
      "4  Data Scientist   Japan      Deloitte             4.0  Data Scientist   \n",
      "\n",
      "       median    low   high   unit  Unnamed: 9  \n",
      "0  ¥1,500,000    ¥1M   ¥18M   / yr         NaN  \n",
      "1  ¥5,000,000    ¥5M    ¥7M   / yr         NaN  \n",
      "2  ¥6,500,000    ¥7M     -    / yr         NaN  \n",
      "3    ¥350,000  ¥300K  ¥402K   / mo         NaN  \n",
      "4  ¥6,250,000    ¥5M    ¥8M   / yr         NaN  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 401190 entries, 0 to 401189\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   role            401190 non-null  object \n",
      " 1   country         401190 non-null  object \n",
      " 2   company         401185 non-null  object \n",
      " 3   company_rating  390055 non-null  float64\n",
      " 4   job_title       401190 non-null  object \n",
      " 5   median          401190 non-null  object \n",
      " 6   low             401190 non-null  object \n",
      " 7   high            401190 non-null  object \n",
      " 8   unit            401190 non-null  object \n",
      " 9   Unnamed: 9      0 non-null       float64\n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 30.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'salaries.csv'\n",
    "data = pd.read_csv(file_path, delimiter='\\t', on_bad_lines='skip')\n",
    "print(data.head())\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa6866c-5eb1-4de8-b200-dac063e5f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Unnamed: 9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ce557f9-52e1-40e7-bba5-6f2e2e9d230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bad line: 1, Content: ['role', 'country', 'company', 'company_rating', 'job_title', 'median', 'low', 'high', 'unit', '']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = 'salaries.csv'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    for i, row in enumerate(reader):\n",
    "        if len(row) != 9: \n",
    "            print(f' Bad line: {i+1}, Content: {row}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3422e919-9c5a-4232-b223-519e8baef9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_18860\\2359774541.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['company_rating'].fillna(mean_rating, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('salaries.csv', delimiter = '\\t')\n",
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data = data.replace('\\xa0', ' ', regex=True) \n",
    "data = data.drop(columns=['Unnamed: 9'])\n",
    "mean_rating = data['company_rating'].mean()\n",
    "data['company_rating'].fillna(mean_rating, inplace=True)\n",
    "if 'company' in data.columns:\n",
    "    data['company'] = data['company'].fillna(\"No Company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5b887-222d-4b77-927b-c4e469489bb9",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "The error you're encountering is a `FileNotFoundError`, which means that the code is trying to read a file named 'glassdoor-salaries.csv', but it cannot find it in the specified directory.\n",
    "\n",
    "To fix this error, you need to ensure that:\n",
    "1. The file 'glassdoor-salaries.csv' exists in the current working directory where your Jupyter Notebook is running.\n",
    "2. If the file is located in a different directory, you should provide the correct path to the file.\n",
    "\n",
    "Would you like me to provide an example of how to specify the correct file path?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a7cedfd-eedb-434a-a299-34e9abe62927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chg_unit(unit):\n",
    "    if unit == ' / yr':\n",
    "        return 'Yearly'\n",
    "    elif unit == ' / mo':\n",
    "        return 'Monthly'\n",
    "    elif unit == ' / hr':\n",
    "        return 'Hourly'\n",
    "data['unit'] = data['unit'].apply(chg_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a66a13c-4bb3-4e98-967c-3aed4c10ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clmn_currency(x):\n",
    "    units = x.split(' ')\n",
    "    if len(units) == 1:\n",
    "        return x[0]\n",
    "    else:\n",
    "        return units[0]\n",
    "data['currency'] = data['median'].apply(clmn_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f530d34-3718-4783-bae0-2fb4cb3e1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_salary(x):\n",
    "    x = str(x)\n",
    "    unit = clmn_currency(x)\n",
    "    x = x.replace(unit,'')\n",
    "    x = x.replace(',','')\n",
    "    x = x.replace('M','000000')\n",
    "    x = x.replace('K','000')\n",
    "    return x              \n",
    "\n",
    "data['median'] = data['median'].apply(format_salary)\n",
    "data['low'] = data['low'].apply(format_salary)\n",
    "data['high'] = data['high'].apply(format_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4879105-e667-4162-a6f1-9ae5bf517c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_salaries.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ce9009b-d748-4534-bc88-8b9990f7a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data saved to 'inventory_stock_data.csv'\n",
      "        date  product_id  stock_level      sales      price  promotion\n",
      "0 2023-01-01           1   112.000000  43.000000  16.002449          0\n",
      "1 2023-01-01           2   455.860668  83.818315  14.328308          0\n",
      "2 2023-01-01           3   891.721081  30.749279  36.609854          0\n",
      "3 2023-01-01           4   312.580983  46.338837  93.929013          0\n",
      "4 2023-01-01           5   159.440121  31.661163  57.089175          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate dates\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Generate sample data\n",
    "n_products = 10\n",
    "n_days = len(date_range)\n",
    "\n",
    "data = {\n",
    "    'date': np.repeat(date_range, n_products),\n",
    "    'product_id': np.tile(np.arange(1, n_products + 1), n_days),\n",
    "    'stock_level': np.random.randint(0, 1000, n_days * n_products),\n",
    "    'sales': np.random.randint(0, 100, n_days * n_products),\n",
    "    'price': np.random.uniform(10, 100, n_days * n_products),\n",
    "    'promotion': np.random.choice([0, 1], n_days * n_products, p=[0.8, 0.2])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add some trends and seasonality\n",
    "df['stock_level'] += df['product_id'] * 10  # Different base stock for each product\n",
    "df['stock_level'] += np.sin(df.index * (2 * np.pi / 365)) * 50  # Yearly seasonality\n",
    "df['sales'] += np.sin(df.index * (2 * np.pi / 7)) * 10  # Weekly seasonality\n",
    "\n",
    "# Ensure stock levels are non-negative\n",
    "df['stock_level'] = df['stock_level'].clip(lower=0)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('inventory_stock_data.csv', index=False)\n",
    "\n",
    "print(\"Sample data saved to 'inventory_stock_data.csv'\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33ec76a6-4997-45ee-91f0-9b2ac37d78ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorAssembler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import datediff, to_date, col\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"InventoryStockAnalysis\").getOrCreate()\n",
    "\n",
    "# Load the data\n",
    "df = spark.read.csv(\"inventory_stock_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Convert date to DateType and calculate days since the start\n",
    "df = df.withColumn(\"date\", to_date(\"date\"))\n",
    "min_date = df.select(min(\"date\")).collect()[0][0]\n",
    "df = df.withColumn(\"days_since_start\", datediff(col(\"date\"), min_date))\n",
    "\n",
    "# Prepare features\n",
    "feature_columns = [\"product_id\", \"days_since_start\", \"sales\", \"price\", \"promotion\"]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df_assembled = assembler.transform(df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = df_assembled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create and train the model\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"stock_level\", numTrees=100)\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol=\"stock_level\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "# Show feature importance\n",
    "feature_importance = model.featureImportances\n",
    "for feature, importance in zip(feature_columns, feature_importance):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")\n",
    "\n",
    "# Example: Predict stock level for a specific product\n",
    "sample_input = df_assembled.select(\"features\").limit(1)\n",
    "sample_prediction = model.transform(sample_input)\n",
    "print(\"Sample prediction:\")\n",
    "sample_prediction.select(\"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d9f8f576-c558-4150-a19e-794e001b15cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "incomplete escape \\U at position 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall -c conda-forge pyspark\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:30\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:128\u001b[0m, in \u001b[0;36mPackagingMagics.conda\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;129m@is_conda_environment\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconda\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the conda package manager within the current kernel.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Usage:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m      %conda install [pkgs]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     conda \u001b[38;5;241m=\u001b[39m _get_conda_like_executable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_command(conda, line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:53\u001b[0m, in \u001b[0;36m_get_conda_like_executable\u001b[1;34m(command)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Otherwise, attempt to extract the executable from conda history.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# This applies in any conda environment.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m history \u001b[38;5;241m=\u001b[39m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*cmd:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?P<command>.*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[create|install]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     history,\n\u001b[0;32m     56\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroupdict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\__init__.py:307\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 307\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:979\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    976\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 979\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    980\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    461\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:862\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    859\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m sub_verbose \u001b[38;5;241m=\u001b[39m ((verbose \u001b[38;5;129;01mor\u001b[39;00m (add_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    861\u001b[0m                \u001b[38;5;129;01mnot\u001b[39;00m (del_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[1;32m--> 862\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    461\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:544\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 544\u001b[0m     code \u001b[38;5;241m=\u001b[39m _escape(source, this, state)\n\u001b[0;32m    545\u001b[0m     subpatternappend(code)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\re\\_parser.py:398\u001b[0m, in \u001b[0;36m_escape\u001b[1;34m(source, escape, state)\u001b[0m\n\u001b[0;32m    396\u001b[0m escape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mgetwhile(\u001b[38;5;241m8\u001b[39m, HEXDIGITS)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincomplete escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m escape, \u001b[38;5;28mlen\u001b[39m(escape))\n\u001b[0;32m    399\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(escape[\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;66;03m# raise ValueError for invalid code\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\U at position 28"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2625d-b31a-4c0e-a373-ae47482ef7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
